{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth # install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git # Also get the latest version Unsloth!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-22T16:59:58.962092Z","iopub.execute_input":"2025-02-22T16:59:58.962308Z","iopub.status.idle":"2025-02-22T17:03:17.488996Z","shell.execute_reply.started":"2025-02-22T16:59:58.962288Z","shell.execute_reply":"2025-02-22T17:03:17.487882Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.2.15-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.2.7 (from unsloth)\n  Downloading unsloth_zoo-2025.2.7-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.3.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.2.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.2.7->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading unsloth-2025.2.15-py3-none-any.whl (188 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.15.1-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.2.7-py3-none-any.whl (107 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.16-py3-none-any.whl (117 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.2 cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 transformers-4.49.0 triton-3.2.0 trl-0.15.1 tyro-0.9.16 unsloth-2025.2.15 unsloth_zoo-2025.2.7 xformers-0.0.29.post3\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-gv2ioial\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-gv2ioial\n  Resolved https://github.com/unslothai/unsloth.git to commit 575ef4d9c094d1c6d13f5414df4e7580347529ee\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.2.15-py3-none-any.whl size=188387 sha256=52ebee637a73a3e1d39496d624130b37726cb2781b219bad9cc1aa9951bd68e8\n  Stored in directory: /tmp/pip-ephem-wheel-cache-3l8a7lpb/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.2.15\n    Uninstalling unsloth-2025.2.15:\n      Successfully uninstalled unsloth-2025.2.15\nSuccessfully installed unsloth-2025.2.15\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch # Import PyTorch\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\nfrom unsloth import is_bfloat16_supported # Checks if the hardware supports bfloat16 precision\n# Hugging Face modules\nfrom huggingface_hub import login # Lets you login to API\nfrom transformers import TrainingArguments # Defines training hyperparameters\nfrom datasets import load_dataset # Lets you load fine-tuning datasets\n# Import weights and biases\nimport wandb\n# Import kaggle secrets\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:03:17.492728Z","iopub.execute_input":"2025-02-22T17:03:17.493023Z","iopub.status.idle":"2025-02-22T17:03:48.888940Z","shell.execute_reply.started":"2025-02-22T17:03:17.492992Z","shell.execute_reply":"2025-02-22T17:03:48.888271Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Initialize Hugging Face & WnB tokens\nuser_secrets = UserSecretsClient() # from kaggle_secrets import UserSecretsClient\nhugging_face_token = user_secrets.get_secret(\"Hugging_Face_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\n# Login to Hugging Face\nlogin(hugging_face_token) # from huggingface_hub import login\n\n# Login to WnB\nwandb.login(key=wnb_token) # import wandb\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on Math Problems', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:03:48.889946Z","iopub.execute_input":"2025-02-22T17:03:48.890149Z","iopub.status.idle":"2025-02-22T17:04:02.282018Z","shell.execute_reply.started":"2025-02-22T17:03:48.890131Z","shell.execute_reply":"2025-02-22T17:04:02.281392Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maryantomar01\u001b[0m (\u001b[33maryantomar01-amity-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250222_170355-wsqwnnia</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems/runs/wsqwnnia' target=\"_blank\">mild-elevator-1</a></strong> to <a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems' target=\"_blank\">https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems/runs/wsqwnnia' target=\"_blank\">https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems/runs/wsqwnnia</a>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Set parameters\nmax_seq_length = 2048 # Define the maximum sequence length a model can handle (i.e. how many tokens can be processed at once)\ndtype = None # Set to default \nload_in_4bit = True # Enables 4 bit quantization — a memory saving optimization \n\n# Load the DeepSeek R1 model and tokenizer using unsloth — imported using: from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",  # Load the pre-trained DeepSeek R1 model (8B parameter version)\n    max_seq_length=max_seq_length, # Ensure the model can process up to 2048 tokens at once\n    dtype=dtype, # Use the default data type (e.g., FP16 or BF16 depending on hardware support)\n    load_in_4bit=load_in_4bit, # Load the model in 4-bit quantization to save memory\n    token=hugging_face_token, # Use hugging face token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:05:40.070636Z","iopub.execute_input":"2025-02-22T17:05:40.070987Z","iopub.status.idle":"2025-02-22T17:06:10.956144Z","shell.execute_reply.started":"2025-02-22T17:05:40.070964Z","shell.execute_reply":"2025-02-22T17:06:10.955265Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14849b6939c6423fa1fbd08dd47f61f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b0a06bfd5f549a7a17c345dd1ef42d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e44620eeaf84450da94921dd90677600"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c88012e103fe463b897f8ad78ea66889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b5a8e229e58461498583aaf067b61cd"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Define a system prompt under prompt_style \nprompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a  expert on mathematics with advanced knowledge in reasoning, problem solving, and planning. \nPlease answer the following mathematical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:09:26.574794Z","iopub.execute_input":"2025-02-22T17:09:26.575095Z","iopub.status.idle":"2025-02-22T17:09:26.579862Z","shell.execute_reply.started":"2025-02-22T17:09:26.575072Z","shell.execute_reply":"2025-02-22T17:09:26.579001Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"****Running Inference on the model****","metadata":{}},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"Task B-1.3. A ship traveling along a river has covered $24 \\mathrm{~km}$ upstream and $28 \\mathrm{~km}$ downstream. \nFor this journey, it took half an hour less than for traveling $30 \\mathrm{~km}$ upstream and $21 \\mathrm{~km}$ downstream, or half an hour more than for traveling $15 \\mathrm{~km}$ upstream and $42 \\mathrm{~km}$ downstream, \nassuming that both the ship and the river move uniformly. Determine the speed of the ship in still water and the speed of the river\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency) \nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=1200, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:12:55.864582Z","iopub.execute_input":"2025-02-22T17:12:55.864931Z","iopub.status.idle":"2025-02-22T17:14:12.884966Z","shell.execute_reply.started":"2025-02-22T17:12:55.864908Z","shell.execute_reply":"2025-02-22T17:14:12.883570Z"}},"outputs":[{"name":"stdout","text":"['<｜begin▁of▁sentence｜>Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a  expert on mathematics with advanced knowledge in reasoning, problem solving, and planning. \\nPlease answer the following mathematical question. \\n\\n### Question:\\nTask B-1.3. A ship traveling along a river has covered $24 \\\\mathrm{~km}$ upstream and $28 \\\\mathrm{~km}$ downstream. \\nFor this journey, it took half an hour less than for traveling $30 \\\\mathrm{~km}$ upstream and $21 \\\\mathrm{~km}$ downstream, or half an hour more than for traveling $15 \\\\mathrm{~km}$ upstream and $42 \\\\mathrm{~km}$ downstream, \\nassuming that both the ship and the river move uniformly. Determine the speed of the ship in still water and the speed of the river\\n\\n### Response:\\n<think>\\nOkay, so I\\'ve got this math problem about a ship traveling upstream and downstream. I need to figure out the ship\\'s speed in still water and the river\\'s current speed. Hmm, let\\'s see.\\n\\nAlright, let me parse the problem again. The ship has gone 24 km upstream and 28 km downstream. The time it took for this journey is half an hour less than the time it would take to travel 30 km upstream and 21 km downstream. Alternatively, it\\'s also half an hour more than the time it would take for 15 km upstream and 42 km downstream. Both trips assume uniform speeds for the ship and the river.\\n\\nSo, let me define some variables to make this clearer. Let me call the ship\\'s speed in still water \"v\" km/h. And the river\\'s current speed \"u\" km/h. When going upstream, the effective speed of the ship is (v - u), and downstream, it\\'s (v + u). That makes sense because the river current aids the ship downstream.\\n\\nNow, the ship first travels 24 km upstream and 28 km downstream. Let\\'s denote the time taken for this trip as T1. So, the time upstream would be 24 / (v - u), and downstream would be 28 / (v + u). Therefore, T1 = 24 / (v - u) + 28 / (v + u).\\n\\nNext, the problem says that this time T1 is half an hour less than the time it would take to travel 30 km upstream and 21 km downstream. Let me denote that time as T2. So, T2 = T1 + 0.5 hours. Wait, no, actually, the problem says T1 is half an hour less than T2, so T2 = T1 + 0.5. So, T2 = 30 / (v - u) + 21 / (v + u).\\n\\nAlternatively, T1 is also half an hour more than the time for another trip, which is 15 km upstream and 42 km downstream. Let me denote that time as T3. So, T3 = T1 - 0.5. Therefore, T3 = 15 / (v - u) + 42 / (v + u).\\n\\nSo now I have three equations:\\n\\n1. T1 = 24 / (v - u) + 28 / (v + u)\\n2. T2 = 30 / (v - u) + 21 / (v + u) = T1 + 0.5\\n3. T3 = 15 / (v - u) + 42 / (v + u) = T1 - 0.5\\n\\nSo, I can set up equations based on these relationships.\\n\\nFrom equation 2: 30/(v - u) + 21/(v + u) = T1 + 0.5\\n\\nBut T1 is equal to 24/(v - u) + 28/(v + u), so substituting:\\n\\n30/(v - u) + 21/(v + u) = 24/(v - u) + 28/(v + u) + 0.5\\n\\nSimilarly, from equation 3: 15/(v - u) + 42/(v + u) = T1 - 0.5\\n\\nAgain, substituting T1:\\n\\n15/(v - u) + 42/(v + u) = 24/(v - u) + 28/(v + u) - 0.5\\n\\nSo now I have two equations with two variables, v and u. Let me write them down.\\n\\nFirst equation:\\n\\n30/(v - u) + 21/(v + u) = 24/(v - u) + 28/(v + u) + 0.5\\n\\nSimplify this equation:\\n\\nSubtract 24/(v - u) and 21/(v + u) from both sides:\\n\\n30/(v - u) - 24/(v - u) + 21/(v + u) - 21/(v + u) = 0.5\\n\\nThis simplifies to:\\n\\n6/(v - u) = 0.5\\n\\nMultiply both sides by (v - u):\\n\\n6 = 0.5(v - u)\\n\\nMultiply both sides by 2:\\n\\n12 = v - u\\n\\nSo, v - u = 12. That\\'s one equation.\\n\\nNow, the second equation:\\n\\n15/(v - u) + 42/(v + u) = 24/(v - u) + 28/(v + u) - 0.5\\n\\nAgain, subtract 24/(v - u) and 28/(v + u) from both sides:\\n\\n15/(v - u) - 24/(v - u) + 42/(v + u) - 28/(v + u) = -0.5\\n\\nSimplify:\\n\\n-9/(v - u) + 14/(v + u) = -0.5\\n\\nSo, -9/(v - u) + 14/(v + u) = -0.5\\n\\nWe already know that v - u = 12, so substitute that:\\n\\n-9/12 + 14/(v + u) = -0.5\\n\\nSimplify -9/12 to -3/4:\\n\\n-3/4 + 14/(v + u) = -0.5\\n\\nAdd 3/4 to both sides:\\n\\n14/(v + u) = -0.5 + 3/4\\n\\nConvert -0.5 to -2/4:\\n\\n14/(v + u) = (-2/4 + 3/4) = 1/4\\n\\nSo, 14/(v']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Creating a test medical question for inference\nquestion = \"\"\"Task B-1.3. A ship traveling along a river has covered $24 \\mathrm{~km}$ upstream and $28 \\mathrm{~km}$ downstream. \nFor this journey, it took half an hour less than for traveling $30 \\mathrm{~km}$ upstream and $21 \\mathrm{~km}$ downstream, or half an hour more than for traveling $15 \\mathrm{~km}$ upstream and $42 \\mathrm{~km}$ downstream, \nassuming that both the ship and the river move uniformly. Determine the speed of the ship in still water and the speed of the river\"\"\"\n\n# Enable optimized inference mode for Unsloth models (improves speed and efficiency)\nFastLanguageModel.for_inference(model)  # Unsloth has 2x faster inference!\n\n# Format the question using the structured prompt (`prompt_style`) and tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")  # Convert input to PyTorch tensor & move to GPU\n\n# Generate a response using the model\noutputs = model.generate(\n    input_ids=inputs.input_ids, # Tokenized input question\n    attention_mask=inputs.attention_mask, # Attention mask to handle padding\n    max_new_tokens=12000, # Limit response length to 1200 tokens (to prevent excessive output)\n    use_cache=True, # Enable caching for faster inference\n)\n\n# Decode the generated output tokens into human-readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the relevant response part (after \"### Response:\")\nprint(response[0].split(\"### Response:\")[1])  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:17:24.675203Z","iopub.execute_input":"2025-02-22T17:17:24.675536Z","iopub.status.idle":"2025-02-22T17:19:52.520420Z","shell.execute_reply.started":"2025-02-22T17:17:24.675511Z","shell.execute_reply":"2025-02-22T17:19:52.519518Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I have this math problem about a ship traveling upstream and downstream. I need to find the speed of the ship in still water and the speed of the river current. Hmm, let me try to break this down.\n\nFirst, I'll note down the given information. The ship has traveled 24 km upstream and 28 km downstream. The time it took for this journey is half an hour less than the time it would take to travel 30 km upstream and 21 km downstream. Alternatively, it's also half an hour more than the time it would take to go 15 km upstream and 42 km downstream. Both the ship and the river move uniformly, so their speeds are constant.\n\nLet me define some variables to make this clearer. Let me denote:\n\n- Let \\( v \\) be the speed of the ship in still water (km/h).\n- Let \\( u \\) be the speed of the river current (km/h).\n\nWhen the ship is moving upstream, its effective speed relative to the ground decreases by the current's speed, so it's \\( v - u \\). Conversely, when moving downstream, its effective speed increases by the current's speed, so it's \\( v + u \\).\n\nNow, time is equal to distance divided by speed. So, the time taken to go upstream 24 km is \\( \\frac{24}{v - u} \\) hours, and downstream 28 km is \\( \\frac{28}{v + u} \\) hours. The total time for this particular journey is the sum of these two, so:\n\nTotal time upstream and downstream = \\( \\frac{24}{v - u} + \\frac{28}{v + u} \\).\n\nAccording to the problem, this total time is half an hour less than the time taken for another journey: traveling 30 km upstream and 21 km downstream. Let me compute the time for that. Upstream time is \\( \\frac{30}{v - u} \\), downstream is \\( \\frac{21}{v + u} \\), so total time is \\( \\frac{30}{v - u} + \\frac{21}{v + u} \\). The problem states that the first total time is half an hour less than this, so:\n\n\\( \\frac{24}{v - u} + \\frac{28}{v + u} = \\left( \\frac{30}{v - u} + \\frac{21}{v + u} \\right) - \\frac{1}{2} \\).\n\nAlternatively, the first total time is half an hour more than the time taken for another journey: traveling 15 km upstream and 42 km downstream. Let me compute that time. Upstream time is \\( \\frac{15}{v - u} \\), downstream is \\( \\frac{42}{v + u} \\), so total time is \\( \\frac{15}{v - u} + \\frac{42}{v + u} \\). The problem states that the first total time is half an hour more than this, so:\n\n\\( \\frac{24}{v - u} + \\frac{28}{v + u} = \\frac{15}{v - u} + \\frac{42}{v + u} + \\frac{1}{2} \\).\n\nNow I have two equations:\n\n1. \\( \\frac{24}{v - u} + \\frac{28}{v + u} = \\frac{30}{v - u} + \\frac{21}{v + u} - \\frac{1}{2} \\)\n2. \\( \\frac{24}{v - u} + \\frac{28}{v + u} = \\frac{15}{v - u} + \\frac{42}{v + u} + \\frac{1}{2} \\)\n\nI can simplify these equations by bringing like terms together.\n\nStarting with equation 1:\n\n\\( \\frac{24}{v - u} + \\frac{28}{v + u} - \\frac{30}{v - u} - \\frac{21}{v + u} = -\\frac{1}{2} \\)\n\nSimplify numerator for each fraction:\n\nFor \\( v - u \\): \\( 24 - 30 = -6 \\)\nFor \\( v + u \\): \\( 28 - 21 = 7 \\)\n\nSo:\n\n\\( \\frac{-6}{v - u} + \\frac{7}{v + u} = -\\frac{1}{2} \\)\n\nSimilarly, for equation 2:\n\n\\( \\frac{24}{v - u} + \\frac{28}{v + u} - \\frac{15}{v - u} - \\frac{42}{v + u} = \\frac{1}{2} \\)\n\nAgain, simplify numerators:\n\nFor \\( v - u \\): \\( 24 - 15 = 9 \\)\nFor \\( v + u \\): \\( 28 - 42 = -14 \\)\n\nSo:\n\n\\( \\frac{9}{v - u} - \\frac{14}{v + u} = \\frac{1}{2} \\)\n\nNow I have two simplified equations:\n\n1. \\( \\frac{-6}{v - u} + \\frac{7}{v + u} = -\\frac{1}{2} \\)\n2. \\( \\frac{9}{v - u} - \\frac{14}{v + u} = \\frac{1}{2} \\)\n\nLet me denote \\( A = v - u \\) and \\( B = v + u \\). Then, the equations become:\n\n1. \\( \\frac{-6}{A} + \\frac{7}{B} = -\\frac{1}{2} \\)\n2. \\( \\frac{9}{A} - \\frac{14}{B} = \\frac{1}{2} \\)\n\nNow, I can solve these two equations simultaneously.\n\nLet me write equation 1 as:\n\n\\( \\frac{7}{B} - \\frac{6}{A} = -\\frac{1}{2} \\) --> equation 1a\n\nand equation 2 as:\n\n\\( \\frac{9}{A} - \\frac{14}{B} = \\frac{1}{2} \\) --> equation 2a\n\nNow, let's add equations 1a and 2a to eliminate the constants:\n\n(7/B - 6/A) + (9/A - 14/B) = (-1/2) + (1/2)\n\nSimplify:\n\n(7/B - 14/B) + (-6/A + 9/A) = 0\n\nWhich simplifies to:\n\n(-7/B) + (3/A) = 0\n\nSo:\n\n3/A = 7/B\n\nCross-multiplying:\n\n3B = 7A\n\nSo, 3B = 7A --> equation 3\n\nNow, from equation 3, we can express B in terms of A:\n\nB = (7/3)A\n\nNow, substitute B = (7/3)A back into one of the equations, say equation 1a:\n\n7/B - 6/A = -1/2\n\nSubstitute B:\n\n7/( (7/3)A ) - 6/A = -1/2\n\nSimplify 7/( (7/3)A ) = 7 * (3/(7A)) = 3/A\n\nSo:\n\n3/A - 6/A = -1/2\n\nWhich simplifies to:\n\n(-3)/A = -1/2\n\nMultiply both sides by -1:\n\n3/A = 1/2\n\nCross-multiplying:\n\n3*2 = A*1 --> A = 6\n\nSo, A = 6 km/h\n\nSince A = v - u = 6\n\nAnd from equation 3, B = (7/3)A = (7/3)*6 = 14 km/h\n\nSo, B = 14 km/h\n\nBut wait, B is v + u, and A is v - u.\n\nSo, we have:\n\nv - u = 6\n\nv + u = 14\n\nNow, adding these two equations:\n\n(v - u) + (v + u) = 6 + 14 --> 2v = 20 --> v = 10 km/h\n\nThen, substituting v = 10 into v - u = 6:\n\n10 - u = 6 --> u = 10 - 6 = 4 km/h\n\nSo, the speed of the ship in still water is 10 km/h, and the speed of the river current is 4 km/h.\n\nLet me verify these results with the original problem to ensure they satisfy both conditions.\n\nFirst, let's compute the total time for the original journey: 24 km upstream and 28 km downstream.\n\nUpstream speed = v - u = 10 - 4 = 6 km/h\nDownstream speed = v + u = 10 + 4 = 14 km/h\n\nTime upstream = 24 / 6 = 4 hours\nTime downstream = 28 / 14 = 2 hours\nTotal time = 4 + 2 = 6 hours\n\nNow, the time for the other journey: 30 km upstream and 21 km downstream.\n\nTime upstream = 30 / 6 = 5 hours\nTime downstream = 21 / 14 = 1.5 hours\nTotal time = 5 + 1.5 = 6.5 hours\n\nAccording to the problem, the original total time is half an hour less than this, which is 6.5 - 0.5 = 6 hours. So, it matches.\n\nFor the second condition, the time for the other journey: 15 km upstream and 42 km downstream.\n\nTime upstream = 15 / 6 = 2.5 hours\nTime downstream = 42 / 14 = 3 hours\nTotal time = 2.5 + 3 = 5.5 hours\n\nThe original total time is half an hour more than this, which is 5.5 + 0.5 = 6 hours. So, it also matches.\n\nTherefore, the solution is correct.\n</think>\n\nThe speed of the ship in still water is \\( \\boxed{10 \\text{ km/h}} \\) and the speed of the river current is \\( \\boxed{4 \\text{ km/h}} \\).<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"**FINE TUNING**","metadata":{}},{"cell_type":"code","source":"# new prompt \nnew_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a  expert on mathematics with advanced knowledge in reasoning, problem solving, and planning. \nPlease answer the following mathematical question. \n\n### Problem:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:33.114099Z","iopub.execute_input":"2025-02-22T17:44:33.114480Z","iopub.status.idle":"2025-02-22T17:44:33.119253Z","shell.execute_reply.started":"2025-02-22T17:44:33.114452Z","shell.execute_reply":"2025-02-22T17:44:33.118599Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Download the dataset using Hugging face\ndataset = load_dataset(\"open-r1/OpenR1-Math-220k\", \"default\", split = \"train[0:1000]\")\n# Get column names\ncolumn_names = dataset.column_names\n\n# Keep only the first three columns\n\nfiltered_dataset = dataset.remove_columns(column_names[3:]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:33.481657Z","iopub.execute_input":"2025-02-22T17:44:33.481933Z","iopub.status.idle":"2025-02-22T17:44:34.580900Z","shell.execute_reply.started":"2025-02-22T17:44:33.481912Z","shell.execute_reply":"2025-02-22T17:44:34.580306Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37b45d4f676349f1bb4cecf75c213e57"}},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"dataset.features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:34.581843Z","iopub.execute_input":"2025-02-22T17:44:34.582060Z","iopub.status.idle":"2025-02-22T17:44:34.588150Z","shell.execute_reply.started":"2025-02-22T17:44:34.582031Z","shell.execute_reply":"2025-02-22T17:44:34.587411Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"{'problem': Value(dtype='string', id=None),\n 'solution': Value(dtype='string', id=None),\n 'answer': Value(dtype='string', id=None),\n 'problem_type': Value(dtype='string', id=None),\n 'question_type': Value(dtype='string', id=None),\n 'source': Value(dtype='string', id=None),\n 'uuid': Value(dtype='string', id=None),\n 'is_reasoning_complete': Sequence(feature=Value(dtype='bool', id=None), length=-1, id=None),\n 'generations': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'correctness_math_verify': Sequence(feature=Value(dtype='bool', id=None), length=-1, id=None),\n 'correctness_llama': Sequence(feature=Value(dtype='bool', id=None), length=-1, id=None),\n 'finish_reasons': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'correctness_count': Value(dtype='int64', id=None),\n 'messages': [{'content': Value(dtype='string', id=None),\n   'role': Value(dtype='string', id=None)}]}"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"# We need to format the dataset to fit our prompt training style \nEOS_TOKEN = tokenizer.eos_token  # Define EOS_TOKEN which the model when to stop generating text during training\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:34.791556Z","iopub.execute_input":"2025-02-22T17:44:34.791793Z","iopub.status.idle":"2025-02-22T17:44:34.797781Z","shell.execute_reply.started":"2025-02-22T17:44:34.791773Z","shell.execute_reply":"2025-02-22T17:44:34.796757Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"# Define formatting prompt function\ndef formatting_prompts_func(examples):  # Takes a batch of dataset examples as input\n    inputs = examples[\"problem\"]       # Extracts the medical question from the dataset\n    cots = examples[\"solution\"]      # Extracts the chain-of-thought reasoning (logical step-by-step explanation)\n    outputs = examples[\"answer\"]      # Extracts the final model-generated response (answer)\n    \n    texts = []  # Initializes an empty list to store the formatted prompts\n    \n    # Iterate over the dataset, formatting each question, reasoning step, and response\n    for input, cot, output in zip(inputs, cots, outputs):  \n        text = new_prompt_style.format(input, cot, output) + EOS_TOKEN  # Insert values into prompt template & append EOS token\n        texts.append(text)  # Add the formatted text to the list\n\n    return {\n        \"text\": texts,  # Return the newly formatted dataset with a \"text\" column containing structured prompts\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:35.509763Z","iopub.execute_input":"2025-02-22T17:44:35.510036Z","iopub.status.idle":"2025-02-22T17:44:35.515887Z","shell.execute_reply.started":"2025-02-22T17:44:35.510014Z","shell.execute_reply":"2025-02-22T17:44:35.514983Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Update dataset formatting\ndataset_finetune = dataset.map(formatting_prompts_func, batched = True)\ndataset_finetune[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:44:36.010019Z","iopub.execute_input":"2025-02-22T17:44:36.010302Z","iopub.status.idle":"2025-02-22T17:44:36.153288Z","shell.execute_reply.started":"2025-02-22T17:44:36.010276Z","shell.execute_reply":"2025-02-22T17:44:36.152350Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3450727f3f4b4c9cabc27c8bdf96d394"}},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a  expert on mathematics with advanced knowledge in reasoning, problem solving, and planning. \\nPlease answer the following mathematical question. \\n\\n### Problem:\\n## Task B-1.3.\\n\\nA ship traveling along a river has covered $24 \\\\mathrm{~km}$ upstream and $28 \\\\mathrm{~km}$ downstream. For this journey, it took half an hour less than for traveling $30 \\\\mathrm{~km}$ upstream and $21 \\\\mathrm{~km}$ downstream, or half an hour more than for traveling $15 \\\\mathrm{~km}$ upstream and $42 \\\\mathrm{~km}$ downstream, assuming that both the ship and the river move uniformly.\\n\\nDetermine the speed of the ship in still water and the speed of the river.\\n\\n### Response:\\n<think>\\n## Solution.\\n\\nLet $t$ be the time required for the boat to travel $24 \\\\mathrm{~km}$ upstream and $28 \\\\mathrm{~km}$ downstream, $v_{R}$ the speed of the river, and $v_{B}$ the speed of the boat. When the boat is traveling upstream, its speed is $v_{B}-v_{R}$, and when it is traveling downstream, its speed is $v_{B}+v_{R}$.\\n\\nSince $t=\\\\frac{s}{v}$, from the given data, we obtain the following system of equations:\\n\\n$\\\\left\\\\{\\\\begin{array}{l}t=\\\\frac{24}{v_{B}-v_{R}}+\\\\frac{28}{v_{B}+v_{R}} \\\\\\\\ t+0.5=\\\\frac{30}{v_{B}-v_{R}}+\\\\frac{21}{v_{B}+v_{R}} \\\\\\\\ t-0.5=\\\\frac{15}{v_{B}-v_{R}}+\\\\frac{42}{v_{B}+v_{R}}\\\\end{array}\\\\right.$\\n\\nBy introducing new variables $x=\\\\frac{3}{v_{B}-v_{R}}, y=\\\\frac{7}{v_{B}+v_{R}}$, the system transforms into:\\n\\n$\\\\left\\\\{\\\\begin{array}{l}t=8 x+4 y \\\\\\\\ t+0.5=10 x+3 y \\\\\\\\ t-0.5=5 x+6 y\\\\end{array}\\\\right.$\\n\\nSubstituting $t$ from the first equation into the remaining two, we get:\\n\\n$\\\\left\\\\{\\\\begin{array}{l}8 x+4 y+0.5=10 x+3 y \\\\\\\\ 8 x+4 y-0.5=5 x+6 y\\\\end{array}\\\\right.$\\n\\n$\\\\left\\\\{\\\\begin{array}{l}2 x-y=0.5 \\\\\\\\ 3 x-2 y=0.5\\\\end{array}\\\\right.$\\n\\nThe solution to the last system is (0.5, 0.5). Then we have:\\n\\n$\\\\frac{3}{v_{B}-v_{R}}=0.5$, hence, $v_{B}-v_{R}=6 \\\\mathrm{~and}$\\n\\n$\\\\frac{7}{v_{B}+v_{R}}=0.5$, hence, $v_{B}+v_{R}=14$.\\n\\nThe speed of the river is $v_{R}=4 \\\\mathrm{~km} / \\\\mathrm{h}$, and the speed of the boat is $v_{B}=10 \\\\mathrm{~km} / \\\\mathrm{h}$.\\n\\n## Note:\\n\\nBy substituting $x=\\\\frac{1}{v_{B}-v_{R}}, y=\\\\frac{1}{v_{B}+v_{R}} \\\\mathrm{~and}$ following the same procedure, the initial system transforms into the system $\\\\left\\\\{\\\\begin{array}{l}6 x-7 y=0.5 \\\\\\\\ 9 x-14 y=0.5\\\\end{array}\\\\right.$\\n\\nThe solution to this system is $\\\\left(\\\\frac{1}{6}, \\\\frac{1}{14}\\\\right)$.\\n</think>\\nv_{R}=4\\\\mathrm{~}/\\\\mathrm{},v_{B}=10\\\\mathrm{~}/\\\\mathrm{}\\n<｜end▁of▁sentence｜>'"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# Apply LoRA (Low-Rank Adaptation) fine-tuning to the model \nFastLanguageModel.for_training(model)\nmodel_lora = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  # LoRA rank: Determines the size of the trainable adapters (higher = more parameters, lower = more efficiency)\n    target_modules=[  # List of transformer layers where LoRA adapters will be applied\n        \"q_proj\",   # Query projection in the self-attention mechanism\n        \"k_proj\",   # Key projection in the self-attention mechanism\n        \"v_proj\",   # Value projection in the self-attention mechanism\n        \"o_proj\",   # Output projection from the attention layer\n        \"gate_proj\",  # Used in feed-forward layers (MLP)\n        \"up_proj\",    # Part of the transformer’s feed-forward network (FFN)\n        \"down_proj\",  # Another part of the transformer’s FFN\n    ],\n    lora_alpha=16,  # Scaling factor for LoRA updates (higher values allow more influence from LoRA layers)\n    lora_dropout=0,  # Dropout rate for LoRA layers (0 means no dropout, full retention of information)\n    bias=\"none\",  # Specifies whether LoRA layers should learn bias terms (setting to \"none\" saves memory)\n    use_gradient_checkpointing=\"unsloth\",  # Saves memory by recomputing activations instead of storing them (recommended for long-context fine-tuning)\n    random_state=3407,  # Sets a seed for reproducibility, ensuring the same fine-tuning behavior across runs\n    use_rslora=False,  # Whether to use Rank-Stabilized LoRA (disabled here, meaning fixed-rank LoRA is used)\n    loftq_config=None,  # Low-bit Fine-Tuning Quantization (LoFTQ) is disabled in this configuration\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:07:36.828642Z","iopub.execute_input":"2025-02-22T18:07:36.828968Z","iopub.status.idle":"2025-02-22T18:07:43.441682Z","shell.execute_reply.started":"2025-02-22T18:07:36.828946Z","shell.execute_reply":"2025-02-22T18:07:43.440954Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# Initialize the fine-tuning trainer — Imported using from trl import SFTTrainer\nfrom trl import SFTTrainer # Trainer for supervised fine-tuning (SFT)\ntrainer = SFTTrainer(\n    model=model_lora,  # The model to be fine-tuned\n    train_dataset=dataset_finetune,  # Dataset used for training\n    peft_config=model_lora,\n    max_seq_length=max_seq_length,  # Defines the maximum sequence length for inputs\n    dataset_text_field=\"text\",  # Specifies which field in the dataset contains training text\n    tokenizer=tokenizer,  # Tokenizer to process text inputs\n  \n    # Define training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,  # Number of examples processed per device (GPU) at a time\n        gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps before updating weights\n        num_train_epochs=1, # Full fine-tuning run\n        warmup_steps=5,  # Gradually increases learning rate for the first 5 steps\n        max_steps=60,  # Limits training to 60 steps (useful for debugging; increase for full fine-tuning)\n        learning_rate=2e-4,  # Learning rate for weight updates (tuned for LoRA fine-tuning)\n        fp16=not is_bfloat16_supported(),  # Use FP16 (if BF16 is not supported) to speed up training\n        bf16=is_bfloat16_supported(),  # Use BF16 if supported (better numerical stability on newer GPUs)\n        logging_steps=10,  # Logs training progress every 10 steps\n        optim=\"adamw_8bit\",  # Uses memory-efficient AdamW optimizer in 8-bit mode\n        weight_decay=0.01,  # Regularization to prevent overfitting\n        lr_scheduler_type=\"linear\",  # Uses a linear learning rate schedule\n        seed=3407,  # Sets a fixed seed for reproducibility\n        output_dir=\"outputs\",  # Directory where fine-tuned model checkpoints will be saved\n    ),\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:07:43.442722Z","iopub.execute_input":"2025-02-22T18:07:43.442992Z","iopub.status.idle":"2025-02-22T18:07:49.087020Z","shell.execute_reply.started":"2025-02-22T18:07:43.442971Z","shell.execute_reply":"2025-02-22T18:07:49.086318Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732dd2184bc84a2b94cce360a8b694bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf719beb516046518f8f3a487471e08e"}},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"import transformers, peft, trl\nprint(\"Transformers:\", transformers.__version__)\nprint(\"PEFT:\", peft.__version__)\nprint(\"TRL:\", trl.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:50:22.154977Z","iopub.execute_input":"2025-02-22T17:50:22.155344Z","iopub.status.idle":"2025-02-22T17:50:22.166572Z","shell.execute_reply.started":"2025-02-22T17:50:22.155319Z","shell.execute_reply":"2025-02-22T17:50:22.165661Z"}},"outputs":[{"name":"stdout","text":"Transformers: 4.49.0\nPEFT: 0.14.0\nTRL: 0.15.1\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"**MODEL TRAINING!!!!!!**","metadata":{}},{"cell_type":"code","source":"# Start the fine-tuning process\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:09:51.097067Z","iopub.execute_input":"2025-02-22T18:09:51.097437Z","iopub.status.idle":"2025-02-22T18:28:28.454892Z","shell.execute_reply.started":"2025-02-22T18:09:51.097409Z","shell.execute_reply":"2025-02-22T18:28:28.454251Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 1,000 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 18:09, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.777800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.602500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.561400</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.491100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.558600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.505000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:29:23.425713Z","iopub.execute_input":"2025-02-22T18:29:23.426016Z","iopub.status.idle":"2025-02-22T18:29:25.031383Z","shell.execute_reply.started":"2025-02-22T18:29:23.425995Z","shell.execute_reply":"2025-02-22T18:29:25.030676Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▃▂▄▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.4905939167854592e+16</td></tr><tr><td>train/epoch</td><td>0.48</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.1955</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.505</td></tr><tr><td>train_loss</td><td>0.58273</td></tr><tr><td>train_runtime</td><td>1115.0667</td></tr><tr><td>train_samples_per_second</td><td>0.43</td></tr><tr><td>train_steps_per_second</td><td>0.054</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">mild-elevator-1</strong> at: <a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems/runs/wsqwnnia' target=\"_blank\">https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems/runs/wsqwnnia</a><br> View project at: <a href='https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems' target=\"_blank\">https://wandb.ai/aryantomar01-amity-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20Math%20Problems</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250222_170355-wsqwnnia/logs</code>"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"Problem = \"\"\"Task B-1.3. A ship traveling along a river has covered $24 \\mathrm{~km}$ upstream and $28 \\mathrm{~km}$ downstream. \nFor this journey, it took half an hour less than for traveling $30 \\mathrm{~km}$ upstream and $21 \\mathrm{~km}$ downstream, or half an hour more than for traveling $15 \\mathrm{~km}$ upstream and $42 \\mathrm{~km}$ downstream, \nassuming that both the ship and the river move uniformly. Determine the speed of the ship in still water and the speed of the river\"\"\"\n\n# Load the inference model using FastLanguageModel (Unsloth optimizes for speed)\nFastLanguageModel.for_inference(model_lora)  # Unsloth has 2x faster inference!\n\n# Tokenize the input question with a specific prompt format and move it to the GPU\ninputs = tokenizer([new_prompt_style.format(Problem, \"\",\"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# Generate a response using LoRA fine-tuned model with specific parameters\noutputs = model_lora.generate(\n    input_ids=inputs.input_ids,          # Tokenized input IDs\n    attention_mask=inputs.attention_mask, # Attention mask for padding handling\n    max_new_tokens=1200,                  # Maximum length for generated response\n    use_cache=True,                        # Enable cache for efficient generation\n)\n\n# Decode the generated response from tokenized format to readable text\nresponse = tokenizer.batch_decode(outputs)\n\n# Extract and print only the model's response part after \"### Response:\"\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T18:35:29.359494Z","iopub.execute_input":"2025-02-22T18:35:29.359829Z","iopub.status.idle":"2025-02-22T18:36:30.197138Z","shell.execute_reply.started":"2025-02-22T18:35:29.359805Z","shell.execute_reply":"2025-02-22T18:36:30.196337Z"}},"outputs":[{"name":"stdout","text":"\n<think>\n\n</think>\n\nTo solve the problem, we need to determine the speed of the ship in still water (\\(v\\)) and the speed of the river (\\(u\\)). Let's denote the speed of the ship in still water as \\(v\\) and the speed of the river as \\(u\\). The total speed of the ship relative to the ground when traveling upstream is \\(v - u\\), and when traveling downstream is \\(v + u\\).\n\nGiven the following information:\n1. The ship travels 24 km upstream and 28 km downstream, taking a total time of 1 hour.\n2. The time taken for this journey is half an hour less than the time taken to travel 30 km upstream and 21 km downstream.\n3. The time taken for this journey is half an hour more than the time taken to travel 15 km upstream and 42 km downstream.\n\nWe set up the equations for the total time for each journey:\n\n1. **First journey (24 km upstream and 28 km downstream):**\n   \\[\n   \\frac{24}{v - u} + \\frac{28}{v + u} = 1\n   \\]\n\n2. **Second journey (30 km upstream and 21 km downstream):**\n   \\[\n   \\frac{30}{v - u} + \\frac{21}{v + u} = 1.5\n   \\]\n\n3. **Third journey (15 km upstream and 42 km downstream):**\n   \\[\n   \\frac{15}{v - u} + \\frac{42}{v + u} = 0.5\n   \\]\n\nWe solve these equations step-by-step:\n\n1. **Express the total time for each journey in terms of \\(T\\):**\n   \\[\n   T = \\frac{24}{v - u} + \\frac{28}{v + u}\n   \\]\n   \\[\n   T = \\frac{30}{v - u} + \\frac{21}{v + u}\n   \\]\n   \\[\n   T = \\frac{15}{v - u} + \\frac{42}{v + u}\n   \\]\n\n2. **Subtract the first equation from the second and third equations to eliminate \\(T\\):**\n   \\[\n   \\frac{30}{v - u} + \\frac{21}{v + u} - \\left(\\frac{24}{v - u} + \\frac{28}{v + u}\\right) = 0.5\n   \\]\n   \\[\n   \\frac{6}{v - u} - \\frac{7}{v + u} = 0.5\n   \\]\n   \\[\n   \\frac{15}{v - u} + \\frac{42}{v + u} - \\left(\\frac{24}{v - u} + \\frac{28}{v + u}\\right) = -0.5\n   \\]\n   \\[\n   \\frac{-9}{v - u} - \\frac{14}{v + u} = -0.5\n   \\]\n\n3. **Solve the resulting equations:**\n   \\[\n   \\frac{6}{v - u} - \\frac{7}{v + u} = 0.5\n   \\]\n   \\[\n   \\frac{6}{v - u} + \\frac{7}{v + u} = 0.5\n   \\]\n\n4. **Add and subtract the equations to find \\(v\\) and \\(u\\):**\n   \\[\n   \\frac{12}{v - u} = 1 \\implies v - u = 12\n   \\]\n   \\[\n   \\frac{14}{v + u} = 1 \\implies v + u = 14\n   \\]\n\n5. **Solve for \\(v\\) and \\(u\\):**\n   \\[\n   v - u = 12\n   \\]\n   \\[\n   v + u = 14\n   \\]\n   \\[\n   v = \\frac{12 + 14}{2} = 13\n   \\]\n   \\[\n   u = \\frac{14 - 12}{2} = 1\n   \\]\n\n### Final Answer\nThe speed of the ship in still water is \\(\\boxed{13 \\mathrm{~km/h}}\\) and the speed of the river is \\(\\boxed{1 \\mathrm{~km/h}}\\).<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}